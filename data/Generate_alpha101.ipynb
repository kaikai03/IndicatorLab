{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "46cc5a85-1564-4f7b-a9e9-b5eb88519cf4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-18T03:28:13.585018Z",
     "iopub.status.busy": "2023-04-18T03:28:13.585018Z",
     "iopub.status.idle": "2023-04-18T03:28:16.210049Z",
     "shell.execute_reply": "2023-04-18T03:28:16.209872Z",
     "shell.execute_reply.started": "2023-04-18T03:28:13.585018Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import os \n",
    "module_path = os.path.abspath(os.path.join('..')) \n",
    "if module_path not in sys.path: \n",
    "    sys.path.append(module_path)\n",
    "\n",
    "import pandas as pd  \n",
    "import numpy as np  \n",
    "\n",
    "import tools.Sample_Tools as smpl\n",
    "import tools.Pretreat_Tools as pretreat\n",
    "from tools.Cacher import (CACHE_TYPE, save_cache,load_cache_adv,load_cache)\n",
    "\n",
    "from base.JuUnits import parallal_task,task_chunk_split\n",
    "from base.JuUnits import excute_for_multidates\n",
    "\n",
    "\n",
    "from QUANTAXIS.QAUtil import DATABASE\n",
    "from QUANTAXIS.QAUtil import  trade_date_sse\n",
    "from QUANTAXIS.QAUtil.QADate_trade import (\n",
    "    QA_util_get_pre_trade_date,\n",
    "    QA_util_get_next_trade_date,\n",
    "    QA_util_if_tradetime\n",
    ")\n",
    "\n",
    "import inspect\n",
    "import ind.Alpha101 as toys\n",
    "\n",
    "from sklearn import linear_model\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%aimport tools.Cacher\n",
    "\n",
    "# def assemble_stocks_by_codes(codes):\n",
    "#     files = list(map(lambda x:x+'_train_qfq',l))\n",
    "#     return pd.concat(list(map(lambda file:load_cache(file,cache_type=CACHE_TYPE.STOCK),files))).sort_index(level=0)\n",
    "\n",
    "def pretreate_data(data):\n",
    "    returns = smpl.get_current_return(data,'close')\n",
    "    returns.name = 'returns'\n",
    "    ret_forward = smpl.get_forward_return(data,'close')\n",
    "    ret_forward.name = 'ret_forward'\n",
    "    # {'Open', 'cap', 'close', 'high', 'ind', 'low', 'returns', 'volume', 'vwap'}\n",
    "    data = pd.concat([data, returns, ret_forward], axis=1)\n",
    "    data = data.assign(vwap=data.amount/(data.volume*100))\n",
    "    data.rename(columns = {\"open\":\"Open\",'market_value':'cap','industry':'ind'}, inplace=True)\n",
    "    data['cap']=data['cap']/data['close'] # 数据取出来的是市值\n",
    "\n",
    "\n",
    "    close_ind = pretreat.neutralize(data.close, data['ind'],categorical=['ind'])\n",
    "    close_ind.name = 'close_ind'\n",
    "    vwap_ind = pretreat.neutralize(data.vwap, data['ind'],categorical=['ind'])\n",
    "    vwap_ind.name = 'vwap_ind'\n",
    "    high_ind = pretreat.neutralize(data.high, data['ind'],categorical=['ind'])\n",
    "    high_ind.name = 'high_ind'\n",
    "    low_ind = pretreat.neutralize(data.low, data['ind'],categorical=['ind'])\n",
    "    low_ind.name = 'low_ind'\n",
    "    volume_ind = pretreat.neutralize(data.volume, data['ind'],categorical=['ind'])\n",
    "    volume_ind.name = 'volume_ind'\n",
    "\n",
    "    adv20 = excute_for_multidates(data.volume, lambda x:x.rolling(20).agg('mean'), level=1)\n",
    "    adv20 = pd.concat([adv20,data['ind']],axis=1).dropna()\n",
    "    adv20_ind = pretreat.neutralize(adv20.volume, adv20['ind'],categorical=['ind'])\n",
    "    adv20_ind.name = 'adv20_ind'\n",
    "\n",
    "    adv40 = excute_for_multidates(data.volume, lambda x:x.rolling(40).agg('mean'), level=1)\n",
    "    adv40 = pd.concat([adv40, data['ind']],axis=1).dropna()\n",
    "    adv40_ind = pretreat.neutralize(adv40.volume, adv40['ind'],categorical=['ind'])\n",
    "    adv40_ind.name = 'adv40_ind'\n",
    "\n",
    "    adv81 = excute_for_multidates(data.volume, lambda x:x.rolling(81).agg('mean'), level=1)\n",
    "    adv81 = pd.concat([adv81, data['ind']],axis=1).dropna()\n",
    "    adv81_ind = pretreat.neutralize(adv81.volume, adv81['ind'],categorical=['ind'])\n",
    "    adv81_ind.name = 'adv81_ind'\n",
    "\n",
    "    co_mixed = ((data.close * 0.60733) + (data.Open * (1 - 0.60733)))\n",
    "    co_mixed_ind = pretreat.neutralize(co_mixed, data['ind'],categorical=['ind'])\n",
    "    co_mixed_ind.name = 'co_mixed_ind'\n",
    "\n",
    "    oh_mixed = ((data.Open * 0.868128) + (data.high * (1 - 0.868128)))\n",
    "    oh_mixed_ind = pretreat.neutralize(oh_mixed, data['ind'],categorical=['ind'])\n",
    "    oh_mixed_ind.name = 'oh_mixed_ind'\n",
    "\n",
    "    lv_mixed = ((data.low * 0.721001) + (data.vwap * (1 - 0.721001)))\n",
    "    lv_mixed_ind = pretreat.neutralize(lv_mixed, data['ind'],categorical=['ind'])\n",
    "    lv_mixed_ind.name = 'lv_mixed_ind'\n",
    "\n",
    "    return pd.concat([data, close_ind, vwap_ind, low_ind, high_ind, volume_ind, adv20_ind, adv40_ind, adv81_ind, co_mixed_ind, oh_mixed_ind, lv_mixed_ind], axis=1)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "02158dab-f12a-46e2-a05b-3f22e14a7040",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-18T03:28:54.630495Z",
     "iopub.status.busy": "2023-04-18T03:28:54.629497Z",
     "iopub.status.idle": "2023-04-18T03:42:05.947056Z",
     "shell.execute_reply": "2023-04-18T03:42:05.946168Z",
     "shell.execute_reply.started": "2023-04-18T03:28:54.630495Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# l = smpl.get_codes_from_blockname('沪深300', sse='all')\n",
    "# df_all =  assemble_stocks_by_codes(l) #文件已合并，不再适用\n",
    "# df_treated = pretreate_data(df_all)\n",
    "\n",
    "# #读取已经缓存的复权数据，并预处理\n",
    "tail = False\n",
    "if tail:\n",
    "    df_all = load_cache('all_tail_qfq',cache_type=CACHE_TYPE.STOCK).sort_index()\n",
    "else:\n",
    "    df_all = load_cache('all_train_qfq',cache_type=CACHE_TYPE.STOCK).sort_index()\n",
    "smpl.optimize_data_type(df_all)\n",
    "df_treated = pretreate_data(df_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "34752a24-d504-4e24-b3d2-b7b8376ecbe7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-18T04:33:34.047698Z",
     "iopub.status.busy": "2023-04-18T04:33:34.047698Z",
     "iopub.status.idle": "2023-04-18T06:59:57.752375Z",
     "shell.execute_reply": "2023-04-18T06:59:57.751427Z",
     "shell.execute_reply.started": "2023-04-18T04:33:34.047698Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now in the main code. Process name is: base.JuUnits\n",
      "base.JuUnits, subpid:18900  pid:3432\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "12c39e0af4ba49c1aeeb575883406c27",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ids = [11,24,38,41,42,47,57,69,80,82,83,88,93,97]\n",
    "# ids = [11,24]\n",
    "\n",
    "ids = np.arange(1,101)\n",
    "np.random.shuffle(ids)\n",
    "def generate_alpha_factors(fun_ids, df=None, type_tail=False):\n",
    "    import inspect\n",
    "    import ind.Alpha101 as a101\n",
    "    from tools.Cacher import (CACHE_TYPE, save_cache,load_cache_adv,load_cache)\n",
    "    from base.JuUnits import excute_for_multidates\n",
    "\n",
    "    for i in fun_ids:\n",
    "        fun_name = 'alpha'+str(i)\n",
    "        params = inspect.signature(getattr(a101, fun_name)).parameters.keys()\n",
    "        indx = excute_for_multidates(df, lambda x: getattr(a101, fun_name)(*[x[param].copy() for param in params]) ,level=1)\n",
    "        indx.name = fun_name\n",
    "        if type_tail:\n",
    "            save_cache('{}_tail'.format(fun_name), indx, cache_type=CACHE_TYPE.FACTOR)\n",
    "        else:\n",
    "            save_cache('{}_train'.format(fun_name), indx, cache_type=CACHE_TYPE.FACTOR)\n",
    "\n",
    "worker=6\n",
    "task = task_chunk_split(ids, worker)\n",
    "results = parallal_task(worker, generate_alpha_factors, task, df=df_treated, type_tail=tail)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
