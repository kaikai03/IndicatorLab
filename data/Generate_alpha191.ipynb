{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "46cc5a85-1564-4f7b-a9e9-b5eb88519cf4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-30T14:32:29.449046Z",
     "iopub.status.busy": "2022-10-30T14:32:29.449046Z",
     "iopub.status.idle": "2022-10-30T14:32:32.069103Z",
     "shell.execute_reply": "2022-10-30T14:32:32.068194Z",
     "shell.execute_reply.started": "2022-10-30T14:32:29.449046Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import os \n",
    "module_path = os.path.abspath(os.path.join('..')) \n",
    "if module_path not in sys.path: \n",
    "    sys.path.append(module_path)\n",
    "\n",
    "import pandas as pd  \n",
    "import numpy as np  \n",
    "\n",
    "import tools.Sample_Tools as smpl\n",
    "import tools.Pretreat_Tools as pretreat\n",
    "from tools.Cacher import (CACHE_TYPE, save_cache,load_cache_adv,load_cache)\n",
    "\n",
    "from base.JuUnits import parallal_task,task_chunk_split\n",
    "from base.JuUnits import excute_for_multidates\n",
    "\n",
    "\n",
    "from QUANTAXIS.QAUtil import DATABASE\n",
    "from QUANTAXIS.QAUtil import  trade_date_sse\n",
    "from QUANTAXIS.QAUtil.QADate_trade import (\n",
    "    QA_util_get_pre_trade_date,\n",
    "    QA_util_get_next_trade_date,\n",
    "    QA_util_if_tradetime\n",
    ")\n",
    "\n",
    "import ind.alpha191 as a191\n",
    "from scipy import stats\n",
    "import statsmodels.api as sm\n",
    "\n",
    "# import cpuinfo\n",
    "# if 'ntel' in cpuinfo.get_cpu_info()['brand_raw']:\n",
    "# from sklearnex import patch_sklearn, unpatch_sklearn\n",
    "# unpatch_sklearn() ##注意，少量数据的线性回归没有优势。慎用，存在内存泄露\n",
    "\n",
    "from sklearn import linear_model\n",
    "\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%aimport ind.alpha191\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "706af604-5dac-4107-8117-d6a83c75ff04",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-31T01:06:20.651880Z",
     "iopub.status.busy": "2022-10-31T01:06:20.651495Z",
     "iopub.status.idle": "2022-10-31T01:06:20.720402Z",
     "shell.execute_reply": "2022-10-31T01:06:20.720402Z",
     "shell.execute_reply.started": "2022-10-31T01:06:20.651880Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def pretreate_data(data):\n",
    "    returns = smpl.get_current_return(data,'close')\n",
    "    returns.name = 'returns'\n",
    "    ret_forward = smpl.get_forward_return(data,'close')\n",
    "    ret_forward.name = 'ret_forward'\n",
    "    # {'Open', 'cap', 'close', 'high', 'ind', 'low', 'returns', 'volume', 'vwap'}\n",
    "    data = pd.concat([data, returns, ret_forward], axis=1)\n",
    "    data = data.assign(vwap=data.amount/(data.volume*100))\n",
    "    data = smpl.add_marketvalue_industry(data)\n",
    "    data.rename(columns = {\"open\":\"Open\",'totalCapital':'cap','industry':'ind'}, inplace=True)\n",
    "    data = smpl.add_report_inds(data,'netAssetsPerShare')\n",
    "    data['pb']=data['close']/data['netAssetsPerShare']\n",
    "    \n",
    "    df_ids = data.index.get_level_values(0)\n",
    "    \n",
    "    benchmark = smpl.get_benchmark('沪深300', start=df_ids.min(), end=df_ids.max()).data\n",
    "    benchmark = benchmark[['open','close']].reset_index('code',drop=True)\n",
    "    data['bm_index_open'] = df_ids.map(benchmark['open'])\n",
    "    data['bm_index_close'] = df_ids.map(benchmark['close'])\n",
    "    return data\n",
    "    # return pd.concat([data, close_ind, vwap_ind, low_ind, high_ind, volume_ind, adv20_ind, adv40_ind, adv81_ind, co_mixed_ind, oh_mixed_ind, lv_mixed_ind], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "02158dab-f12a-46e2-a05b-3f22e14a7040",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-31T01:05:55.897751Z",
     "iopub.status.busy": "2022-10-31T01:05:55.896865Z",
     "iopub.status.idle": "2022-10-31T01:05:57.461895Z",
     "shell.execute_reply": "2022-10-31T01:05:57.461095Z",
     "shell.execute_reply.started": "2022-10-31T01:05:55.897751Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def assemble_stocks_by_codes(codes):\n",
    "    files = list(map(lambda x:x+'_train_qfq',codes))\n",
    "    return pd.concat(list(map(lambda file:load_cache(file,cache_type=CACHE_TYPE.STOCK),files))).sort_index(level=0)\n",
    "\n",
    "l = smpl.get_codes_from_blockname('沪深300', sse='all')\n",
    "df_all =  assemble_stocks_by_codes(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f45982ae-740c-4726-8571-59aec054f097",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-31T01:06:26.122790Z",
     "iopub.status.busy": "2022-10-31T01:06:26.122092Z",
     "iopub.status.idle": "2022-10-31T01:06:50.623941Z",
     "shell.execute_reply": "2022-10-31T01:06:50.622928Z",
     "shell.execute_reply.started": "2022-10-31T01:06:26.122790Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_treated = pretreate_data(df_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "id": "34752a24-d504-4e24-b3d2-b7b8376ecbe7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-30T14:31:47.368893Z",
     "iopub.status.busy": "2022-10-30T14:31:47.367704Z",
     "iopub.status.idle": "2022-10-30T14:31:47.449722Z",
     "shell.execute_reply": "2022-10-30T14:31:47.449722Z",
     "shell.execute_reply.started": "2022-10-30T14:31:47.368893Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ids = [11,24,38,41,42,47,57,69,80,82,83,88,93,97]\n",
    "# ids = [92,157,149,191]\n",
    "\n",
    "# ['000001','601728','000002','601825', '601868']\n",
    "ids = np.arange(1,192)\n",
    "np.random.shuffle(ids)\n",
    "\n",
    "def generate_alpha_factors(fun_ids, df=None):\n",
    "    import ind.alpha191 as a191\n",
    "    from tools.Cacher import (CACHE_TYPE, save_cache,load_cache_adv,load_cache)\n",
    "    from base.JuUnits import excute_for_multidates\n",
    "    import numpy as np\n",
    "\n",
    "    for i in fun_ids:\n",
    "    # for i in ids:\n",
    "        fun_name = 'alpha'+ '0'*(3- int(np.log10(i)+1)) +str(i)\n",
    "        if fun_name != 'alpha030':\n",
    "            indx = excute_for_multidates(df, lambda x: getattr(a191, fun_name)(x) ,level=1)\n",
    "        else:\n",
    "            indx = getattr(a191, fun_name)(df)\n",
    "        # indx = excute_for_multidates(df_treated.loc[(slice(None),['000001','601728','000002','601825', '601868']),:], lambda x: getattr(a191, fun_name)(x) ,level=1)\n",
    "        indx.name = '191_'+fun_name\n",
    "        save_cache('{}_train'.format(indx.name), indx, cache_type=CACHE_TYPE.FACTOR)\n",
    "        # print(indx)\n",
    "\n",
    "# worker=6\n",
    "# task = task_chunk_split(ids, worker)\n",
    "# results = parallal_task(worker, generate_alpha_factors, task, df=df_treated)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "ee532e13-0455-4fc2-9ea4-102daec3c77e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-28T09:44:07.018303Z",
     "iopub.status.busy": "2022-10-28T09:44:07.018303Z",
     "iopub.status.idle": "2022-10-28T09:44:07.094861Z",
     "shell.execute_reply": "2022-10-28T09:44:07.094021Z",
     "shell.execute_reply.started": "2022-10-28T09:44:07.018303Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# excute_for_multidates(df_treated.sort_index(), lambda x: a191.alpha011(x) ,level=1)\n",
    "def STD(data, windows):\n",
    "    return data.rolling(window=windows, min_periods=windows).std()\n",
    "def MEAN(data, windows):\n",
    "    return data.rolling(window=windows, min_periods=windows).mean()\n",
    "def DELTA(data, windows):\n",
    "    return data.diff(4)\n",
    "def SEQUENCE(n):\n",
    "    return pd.Series(np.arange(1,n+1))\n",
    "\n",
    "def SMA(data,windows,alpha):\n",
    "    return data.ewm(adjust=False, alpha=float(alpha)/windows, min_periods=windows, ignore_na=False).mean()\n",
    "\n",
    "def REGBETA(xs, y, n):\n",
    "    assert len(y)>=n,  'len(y)!>=n !!!'+ str(y.index[0])\n",
    "    regress = linear_model.LinearRegression(fit_intercept=False)\n",
    "    def reg(X,Y):\n",
    "        try:\n",
    "            if len(Y)>len(X):\n",
    "                Y_ =  Y[X.index]\n",
    "                if Y_.isnull().any():\n",
    "                    return np.nan\n",
    "                res = regress.fit(X.values.reshape(-1, 1), Y_.values.reshape(-1, 1)).coef_[0]\n",
    "            else:\n",
    "                # if Y.isnull().any():\n",
    "                #     return np.nan\n",
    "                res = regress.fit(X.values.reshape(-1, 1), Y.values.reshape(-1, 1)).coef_[0]\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            return np.nan\n",
    "        return res\n",
    "    return xs.rolling(window=n, min_periods=n).apply(lambda x:reg(x,y))\n",
    "\n",
    "\n",
    "def COVIANCE(A,B,d):\n",
    "    se = pd.Series(np.arange(len(A.index)),index=A.index)\n",
    "    se = se.rolling(5).apply(lambda x: A.iloc[x].cov(B.iloc[x]))\n",
    "    return se\n",
    "\n",
    "def CORR(A,B,d):\n",
    "    se = pd.Series(np.arange(len(A.index)),index=A.index)\n",
    "    se = se.rolling(5).apply(lambda x: A.iloc[x].corr(B.iloc[x]))\n",
    "    return se\n",
    "\n",
    "\n",
    "def alpha149(data, dependencies=['close', 'bm_index_close'], max_window=253):\n",
    "    # REGBETA(FILTER(RET,BANCHMARK_INDEX_CLOSE<DELAY(BANCHMARK_INDEX_CLOSE,1)),\n",
    "    # FILTER(BANCHMARK_INDEX_CLOSE/DELAY(BANCHMARK_INDEX_CLOSE,1)-1,BANCHMARK_INDEX_CLOSE<DELAY(BANCHMARK_INDEX_CLOSE,1)),252)\n",
    "    if len(data)< max_window:\n",
    "        return pd.Series(np.nan,index=data.index)\n",
    "    bm = data['bm_index_close']\n",
    "    bm = (bm.diff(1) < 0.0)\n",
    "    part1 = data['close'].pct_change(periods=1)[bm]\n",
    "    part2 = data['close'].rolling(252).mean().pct_change(periods=1)[bm]\n",
    "    try:\n",
    "        alpha = REGBETA(part1,part2,252)\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        return pd.Series(np.nan,index=data.index)\n",
    "    return alpha\n",
    "\n",
    "# print(alpha181(df_treated.loc[(slice(None),['000001']),:]).to_list())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "4a34ce6b-49d9-48da-bb31-a59115bc316d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-31T09:57:07.622091Z",
     "iopub.status.busy": "2022-10-31T09:57:07.619018Z",
     "iopub.status.idle": "2022-10-31T09:57:07.790111Z",
     "shell.execute_reply": "2022-10-31T09:57:07.789185Z",
     "shell.execute_reply.started": "2022-10-31T09:57:07.622091Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# a = df_treated.loc[(slice(None),['000001']),:]\n",
    "# excute_for_multidates(df_treated, lambda x: getattr(a191, 'alpha149')(x) ,level=1)\n",
    "# x = excute_for_multidates(df_treated, lambda x: alpha149(x) ,level=1)\n",
    "# x = excute_for_multidates(df_treated.loc[(slice(None),['000001','605499','601728','601825','601868']),:], lambda x: alpha149(x) ,level=1)\n",
    "# x.sort_index()\n",
    "\n",
    "# with pd.option_context('display.max_rows', None): \n",
    "#     print(x.sort_index())\n",
    "\n",
    "def alpha030(data, dependencies=['close', 'PB', 'MktValue'], max_window=81):\n",
    "    if not 'code' in df_treated.index.names:\n",
    "        print('alpha030 needs stocks more than one')\n",
    "        return None\n",
    "    elif len(df_treated.index.get_level_values('code').unique())<=1:\n",
    "        print('alpha030 needs stocks more than one')\n",
    "\n",
    "    ## 不是单票的，以后再说\n",
    "    # WMA((REGRESI(RET,MKT,SMB,HML,60))^2,20)\n",
    "    # 即特质性收益\n",
    "    # MKT 为市值加权的市场平均收益率，\n",
    "    # SMB 为市值最小的30%的股票的平均收益减去市值最大的30%的股票的平均收益，\n",
    "    # HML 为PB最高的30%的股票的平均收益减去PB最低的30%的股票的平均收益    ret = data['close'].pct_change(periods=1).fillna(0.0)\n",
    "    \n",
    "    def alpha_30_deal(d_):\n",
    "        print(d_.index)\n",
    "        return d_\n",
    "        mkt_ret = (ret * d_['cap']).sum(axis=1) / d_['cap'].sum(axis=1)\n",
    "        me30 = (d_['cap'].T <= d_['cap'].quantile(0.3, axis=1)).T\n",
    "        me70 = (d_['cap'].T >= d_['cap'].quantile(0.7, axis=1)).T\n",
    "        pb30 = (d_['pb'].T <= d_['pb'].quantile(0.3, axis=1)).T\n",
    "        pb70 = (d_['pb'].T >= d_['pb'].quantile(0.7, axis=1)).T\n",
    "        smb_ret = ret[me30].mean(axis=1, skipna=True) - ret[me70].mean(axis=1, skipna=True)\n",
    "        hml_ret = ret[pb70].mean(axis=1, skipna=True) - ret[pb30].mean(axis=1, skipna=True)\n",
    "        xs = pd.concat([mkt_ret, smb_ret, hml_ret], axis=1)\n",
    "        idxs = pd.Series(data=range(len(d_['close'].index)), index=d_['close'].index)\n",
    "\n",
    "        def multi_var_linregress(idx, y, xs):\n",
    "            X = xs.iloc[idx]\n",
    "            Y = y.iloc[idx]\n",
    "            X = sm.add_constant(X)\n",
    "            try:\n",
    "                res = np.array(sm.OLS(Y, X).fit().resid)\n",
    "            except Exception as e:\n",
    "                return pd.Series(np.nan,index=data.index)\n",
    "            return res[-1]\n",
    "\n",
    "        # print(xs.tail(5), ret.tail(5))\n",
    "        residual = [idxs.rolling(window=60, min_periods=60).apply(lambda x: multi_var_linregress(x, ret[col], xs)) for col in ret.columns]\n",
    "        residual = pd.concat(residual, axis=1)\n",
    "        residual.columns = ret.columns\n",
    "\n",
    "        # w = preprocessing.normalize(np.array([i for i in range(1, 21)]), norm='l1', axis=1).reshape(-1)\n",
    "        # w = preprocessing.normalize(np.array([i for i in range(1, 21)]).reshape(-1, 1), norm='l1', axis=0).reshape(-1)\n",
    "        w = np.array(range(1, 21))\n",
    "        w = w/w.sum()\n",
    "        alpha = (residual ** 2).rolling(window=20, min_periods=20).apply(lambda x: np.dot(x, w))\n",
    "        return alpha\n",
    "    \n",
    "\n",
    "    return excute_for_multidates(data, lambda x: alpha_30_deal(x),level=0)\n",
    "\n",
    "# alpha030(df_treated.loc[(slice(None),['000001','000002']),:])\n",
    "\n",
    "# def alpha186(data, dependencies=['ADXR'], max_window=1):\n",
    "#     return None\n",
    "#     # \\u5c31\\u662fADXR\n",
    "# #     (MEAN(ABS(SUM((LD>0  &  LD>HD)?LD:0,14)*100/SUM(TR,14)-SUM((HD>0  &\n",
    "# # HD>LD)?HD:0,14)*100/SUM(TR,14))/(SUM((LD>0  &  LD>HD)?LD:0,14)*100/SUM(TR,14)+SUM((HD>0  &\n",
    "# # HD>LD)?HD:0,14)*100/SUM(TR,14))*100,6)+DELAY(MEAN(ABS(SUM((LD>0  &\n",
    "# # LD>HD)?LD:0,14)*100/SUM(TR,14)-SUM((HD>0  &  HD>LD)?HD:0,14)*100/SUM(TR,14))/(SUM((LD>0  &\n",
    "# # LD>HD)?LD:0,14)*100/SUM(TR,14)+SUM((HD>0 & HD>LD)?HD:0,14)*100/SUM(TR,14))*100,6),6))/2\n",
    "#     return data['ADXR'].iloc[-1]\n",
    "\n",
    "# excute_for_multidates(df_treated.loc[(slice(None),['000001','000002']),:], lambda x: a191.alpha021(x) ,level=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "71c978b0-5e14-4ec8-909a-9d02acdaaaf4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-31T11:18:34.326367Z",
     "iopub.status.busy": "2022-10-31T11:18:34.325369Z",
     "iopub.status.idle": "2022-10-31T11:18:34.429232Z",
     "shell.execute_reply": "2022-10-31T11:18:34.428400Z",
     "shell.execute_reply.started": "2022-10-31T11:18:34.326367Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: []"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df_treated.index.get_level_values(1).unique().to_list()\n",
    "# '601728',\n",
    "#  '601825',\n",
    "#  '601868']\n",
    "# alpha149(df_treated.loc[(slice(None),['601825']),:])\n",
    "\n",
    "\n",
    "# a = df_treated.loc[(pd.Timestamp('2017-01-05'),['000001','000002']),:]\n",
    "a = df_treated.loc[(pd.Timestamp('2017-01-05'),['000001', '000002', '000063', '000066', '000069', '000100', '000157','000166', '000301', '000333']),:]\n",
    "\n",
    "def test(d):\n",
    "    # ret = d['returns']\n",
    "    # mkt_ret = (ret * d['cap']).sum() / d['cap'].sum()\n",
    "    # return mkt_ret\n",
    "    me30 = (d['cap'] <= d['cap'].quantile(0.3))\n",
    "    me70 = (d['cap'] >= d['cap'].quantile(0.7))\n",
    "    pb30 = (d['pb'] <= d['pb'].quantile(0.3))\n",
    "    pb70 = (d['pb'] >= d['pb'].quantile(0.7))\n",
    "    \n",
    "    \n",
    "excute_for_multidates(a, lambda x: test(x),level=0)\n",
    "# df_treated.loc[(pd.Timestamp('2017-01-05'),['000001','000002']),:].sort_index()[['returns','cap']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b1f7cda8-2ab9-4d4f-9ef8-f0d5c2ea2c4a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-30T14:33:53.165193Z",
     "iopub.status.busy": "2022-10-30T14:33:53.165193Z",
     "iopub.status.idle": "2022-10-30T14:33:53.238667Z",
     "shell.execute_reply": "2022-10-30T14:33:53.237148Z",
     "shell.execute_reply.started": "2022-10-30T14:33:53.165193Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 0 ns\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# df_all.loc[(slice('2017-01-10'),['000001','000002','000063']),:]\n",
    "# pd.concat(indxes,axis=1).sort_index().loc[(slice('2017-01-15'),['000001','000002','000063']),:]\n",
    "\n",
    "# # a = load_cache('alpha11_train', cache_type=CACHE_TYPE.FACTOR)\n",
    "# # b = load_cache('alpha24_train', cache_type=CACHE_TYPE.FACTOR)\n",
    "# pd.concat([a,b],axis=1).sort_index().loc[(slice('2017-01-20'),['000001','000002']),:]\n",
    "# pd.Series(-1,index=df_treated.loc[(slice(None),['000001']),:].index,dtype=np.dtype('int8'))\n",
    "\n",
    "# a=alpha004(df_treated.loc[(slice(None),['000001']),:])\n",
    "# a.rolling(window=5, min_periods=5).corr(a).to_list()\n",
    "# a.to_list()\n",
    "# a.rolling(window=5, min_periods=5).apply(lambda x:x.corr(a[x.index])).to_list()\n",
    "# a[0:50].rolling(window=5, min_periods=5).apply(lambda x:print(x.corr(a[x.index])))\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
