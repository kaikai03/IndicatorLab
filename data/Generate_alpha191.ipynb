{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "46cc5a85-1564-4f7b-a9e9-b5eb88519cf4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-07T02:18:52.831600Z",
     "iopub.status.busy": "2022-11-07T02:18:52.831600Z",
     "iopub.status.idle": "2022-11-07T02:18:55.204253Z",
     "shell.execute_reply": "2022-11-07T02:18:55.204056Z",
     "shell.execute_reply.started": "2022-11-07T02:18:52.831600Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import os \n",
    "module_path = os.path.abspath(os.path.join('..')) \n",
    "if module_path not in sys.path: \n",
    "    sys.path.append(module_path)\n",
    "\n",
    "import pandas as pd  \n",
    "import numpy as np  \n",
    "\n",
    "import tools.Sample_Tools as smpl\n",
    "import tools.Pretreat_Tools as pretreat\n",
    "from tools.Cacher import (CACHE_TYPE, save_cache,load_cache_adv,load_cache)\n",
    "\n",
    "from base.JuUnits import parallal_task,task_chunk_split\n",
    "from base.JuUnits import excute_for_multidates\n",
    "\n",
    "\n",
    "from QUANTAXIS.QAUtil import DATABASE\n",
    "from QUANTAXIS.QAUtil import  trade_date_sse\n",
    "from QUANTAXIS.QAUtil.QADate_trade import (\n",
    "    QA_util_get_pre_trade_date,\n",
    "    QA_util_get_next_trade_date,\n",
    "    QA_util_if_tradetime\n",
    ")\n",
    "\n",
    "import ind.alpha191 as a191\n",
    "from scipy import stats\n",
    "import statsmodels.api as sm\n",
    "\n",
    "# import cpuinfo\n",
    "# if 'ntel' in cpuinfo.get_cpu_info()['brand_raw']:\n",
    "# from sklearnex import patch_sklearn, unpatch_sklearn\n",
    "# unpatch_sklearn() ##注意，少量数据的线性回归没有优势。慎用，存在内存泄露\n",
    "\n",
    "from sklearn import linear_model\n",
    "\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%aimport ind.alpha191\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "706af604-5dac-4107-8117-d6a83c75ff04",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-07T02:18:55.205027Z",
     "iopub.status.busy": "2022-11-07T02:18:55.205027Z",
     "iopub.status.idle": "2022-11-07T02:18:55.284829Z",
     "shell.execute_reply": "2022-11-07T02:18:55.284014Z",
     "shell.execute_reply.started": "2022-11-07T02:18:55.205027Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def pretreate_data(data):\n",
    "    returns = smpl.get_current_return(data,'close')\n",
    "    returns.name = 'returns'\n",
    "    ret_forward = smpl.get_forward_return(data,'close')\n",
    "    ret_forward.name = 'ret_forward'\n",
    "    # {'Open', 'cap', 'close', 'high', 'ind', 'low', 'returns', 'volume', 'vwap'}\n",
    "    data = pd.concat([data, returns, ret_forward], axis=1)\n",
    "    data = data.assign(vwap=data.amount/(data.volume*100))\n",
    "    data = smpl.add_marketvalue_industry(data)\n",
    "    data.rename(columns = {\"open\":\"Open\",'totalCapital':'cap','industry':'ind'}, inplace=True)\n",
    "    data = smpl.add_report_inds(data,'netAssetsPerShare')\n",
    "    data['pb']=data['close']/data['netAssetsPerShare']\n",
    "    \n",
    "    df_ids = data.index.get_level_values(0)\n",
    "    \n",
    "    benchmark = smpl.get_benchmark('沪深300', start=df_ids.min(), end=df_ids.max()).data\n",
    "    benchmark = benchmark[['open','close']].reset_index('code',drop=True)\n",
    "    data['bm_index_open'] = df_ids.map(benchmark['open'])\n",
    "    data['bm_index_close'] = df_ids.map(benchmark['close'])\n",
    "    return data\n",
    "    # return pd.concat([data, close_ind, vwap_ind, low_ind, high_ind, volume_ind, adv20_ind, adv40_ind, adv81_ind, co_mixed_ind, oh_mixed_ind, lv_mixed_ind], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "02158dab-f12a-46e2-a05b-3f22e14a7040",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-07T02:18:55.285827Z",
     "iopub.status.busy": "2022-11-07T02:18:55.285267Z",
     "iopub.status.idle": "2022-11-07T02:18:56.783097Z",
     "shell.execute_reply": "2022-11-07T02:18:56.782473Z",
     "shell.execute_reply.started": "2022-11-07T02:18:55.285827Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def assemble_stocks_by_codes(codes):\n",
    "    files = list(map(lambda x:x+'_train_qfq',codes))\n",
    "    return pd.concat(list(map(lambda file:load_cache(file,cache_type=CACHE_TYPE.STOCK),files))).sort_index(level=0)\n",
    "\n",
    "l = smpl.get_codes_from_blockname('沪深300', sse='all')\n",
    "df_all =  assemble_stocks_by_codes(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f45982ae-740c-4726-8571-59aec054f097",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-07T02:18:57.002831Z",
     "iopub.status.busy": "2022-11-07T02:18:57.002831Z",
     "iopub.status.idle": "2022-11-07T02:19:21.781384Z",
     "shell.execute_reply": "2022-11-07T02:19:21.780154Z",
     "shell.execute_reply.started": "2022-11-07T02:18:57.002831Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_treated = pretreate_data(df_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "34752a24-d504-4e24-b3d2-b7b8376ecbe7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-07T02:19:21.783273Z",
     "iopub.status.busy": "2022-11-07T02:19:21.783164Z",
     "iopub.status.idle": "2022-11-07T02:38:25.704648Z",
     "shell.execute_reply": "2022-11-07T02:38:25.703683Z",
     "shell.execute_reply.started": "2022-11-07T02:19:21.783273Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now in the main code. Process name is: base.JuUnits\n",
      "base.JuUnits, subpid:7744  pid:23192\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d790df7a069044e386d6f3ad887c2008",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ids = [11,24,38,41,42,47,57,69,80,82,83,88,93,97]\n",
    "# ids = [92,157,149,191]\n",
    "\n",
    "# ['000001','601728','000002','601825', '601868']\n",
    "ids = np.arange(1,192)\n",
    "np.random.shuffle(ids)\n",
    "\n",
    "def generate_alpha_factors(fun_ids, df=None):\n",
    "    import ind.alpha191 as a191\n",
    "    from tools.Cacher import (CACHE_TYPE, save_cache,load_cache_adv,load_cache)\n",
    "    from base.JuUnits import excute_for_multidates\n",
    "    import numpy as np\n",
    "\n",
    "    for i in fun_ids:\n",
    "    # for i in ids:\n",
    "        fun_name = 'alpha'+ '0'*(3- int(np.log10(i)+1)) +str(i)\n",
    "        if fun_name != 'alpha030':\n",
    "            indx = excute_for_multidates(df, lambda x: getattr(a191, fun_name)(x) ,level=1)\n",
    "        else:\n",
    "            indx = getattr(a191, fun_name)(df)\n",
    "        # indx = excute_for_multidates(df_treated.loc[(slice(None),['000001','601728','000002','601825', '601868']),:], lambda x: getattr(a191, fun_name)(x) ,level=1)\n",
    "        indx.name = '191_'+fun_name\n",
    "        save_cache('{}_train'.format(indx.name), indx, cache_type=CACHE_TYPE.FACTOR)\n",
    "        # print(indx)\n",
    "\n",
    "worker=6\n",
    "task = task_chunk_split(ids, worker)\n",
    "results = parallal_task(worker, generate_alpha_factors, task, df=df_treated)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "ee532e13-0455-4fc2-9ea4-102daec3c77e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-04T11:10:32.404724Z",
     "iopub.status.busy": "2022-11-04T11:10:32.403816Z",
     "iopub.status.idle": "2022-11-04T11:10:32.624139Z",
     "shell.execute_reply": "2022-11-04T11:10:32.623810Z",
     "shell.execute_reply.started": "2022-11-04T11:10:32.404724Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# excute_for_multidates(df_treated.sort_index(), lambda x: a191.alpha011(x) ,level=1)\n",
    "def STD(data, windows):\n",
    "    return data.rolling(window=windows, min_periods=windows).std()\n",
    "def MEAN(data, windows):\n",
    "    return data.rolling(window=windows, min_periods=windows).mean()\n",
    "def DELTA(data, windows):\n",
    "    return data.diff(4)\n",
    "def SEQUENCE(n):\n",
    "    return pd.Series(np.arange(1,n+1))\n",
    "\n",
    "def SMA(data,windows,alpha):\n",
    "    return data.ewm(adjust=False, alpha=float(alpha)/windows, min_periods=windows, ignore_na=False).mean()\n",
    "\n",
    "def REGBETA(xs, y, n):\n",
    "    assert len(y)>=n,  'len(y)!>=n !!!'+ str(y.index[0])\n",
    "    regress = linear_model.LinearRegression(fit_intercept=False)\n",
    "    def reg(X,Y):\n",
    "        try:\n",
    "            if len(Y)>len(X):\n",
    "                Y_ =  Y[X.index]\n",
    "                if Y_.isnull().any():\n",
    "                    return np.nan\n",
    "                res = regress.fit(X.values.reshape(-1, 1), Y_.values.reshape(-1, 1)).coef_[0]\n",
    "            else:\n",
    "                # if Y.isnull().any():\n",
    "                #     return np.nan\n",
    "                res = regress.fit(X.values.reshape(-1, 1), Y.values.reshape(-1, 1)).coef_[0]\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            return np.nan\n",
    "        return res\n",
    "    return xs.rolling(window=n, min_periods=n).apply(lambda x:reg(x,y))\n",
    "\n",
    "\n",
    "def COVIANCE(A,B,d):\n",
    "    se = pd.Series(np.arange(len(A.index)),index=A.index)\n",
    "    se = se.rolling(5).apply(lambda x: A.iloc[x].cov(B.iloc[x]))\n",
    "    return se\n",
    "\n",
    "def CORR(A,B,d):\n",
    "    se = pd.Series(np.arange(len(A.index)),index=A.index)\n",
    "    se = se.rolling(5).apply(lambda x: A.iloc[x].corr(B.iloc[x]))\n",
    "    return se\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "71c978b0-5e14-4ec8-909a-9d02acdaaaf4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-04T10:33:20.890022Z",
     "iopub.status.busy": "2022-11-04T10:33:20.889023Z",
     "iopub.status.idle": "2022-11-04T10:33:21.290767Z",
     "shell.execute_reply": "2022-11-04T10:33:21.290767Z",
     "shell.execute_reply.started": "2022-11-04T10:33:20.890022Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "date        code  \n",
       "2017-01-04  000001          NaN\n",
       "2017-01-05  000001          NaN\n",
       "2017-01-06  000001          NaN\n",
       "2017-01-09  000001          NaN\n",
       "2017-01-10  000001          NaN\n",
       "                        ...    \n",
       "2021-12-24  000333    13.081014\n",
       "2021-12-27  000333    13.642905\n",
       "2021-12-28  000333    15.457109\n",
       "2021-12-29  000333    14.600930\n",
       "2021-12-30  000333    11.121865\n",
       "Length: 11792, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# df_treated.index.get_level_values(1).unique().to_list()\n",
    "# '601728',\n",
    "#  '601825',\n",
    "#  '601868']\n",
    "# alpha149(df_treated.loc[(slice(None),['601825']),:])\n",
    "\n",
    "a = df_treated#.loc[(slice(None),['000001','000002']),:]\n",
    "# a = df_treated.loc[(pd.Timestamp('2017-01-05'),['000001','000002']),:]\n",
    "# a = df_treated.loc[([pd.Timestamp('2017-01-05'),pd.Timestamp('2017-01-06')],['000001', '000002', '000063', '000066', '000069', '000100', '000157','000166', '000301', '000333']),:]\n",
    "# a = df_treated.loc[([pd.Timestamp('2017-01-05'),pd.Timestamp('2017-01-06')],['000001', '000002', '000063', '000066', '000069', '000100', '000157','000166', '000301', '000333']),:]\n",
    "\n",
    "# d_ = d.dropna(subset=['returns'],axis=0)\n",
    "\n",
    "def alpha186(data, dependencies=['low','high','close'], max_window=20):\n",
    "    # 就是ADXR\n",
    "#     (MEAN(ABS(SUM((LD>0 & LD>HD)?LD:0,14)*100/SUM(TR,14) - SUM((HD>0 & HD>LD)?HD:0,14)*100/SUM(TR,14)) \n",
    "#     /\n",
    "#     (SUM((LD>0  &  LD>HD)?LD:0,14)*100/SUM(TR,14) + SUM((HD>0 & HD>LD)?HD:0,14)*100/SUM(TR,14))*100,6)\n",
    "#     +\n",
    "#     DELAY(MEAN(ABS(SUM((LD>0 & LD>HD)?LD:0,14)*100/SUM(TR,14) - SUM((HD>0 & HD>LD)?HD:0,14)*100/SUM(TR,14)) \n",
    "#            / (SUM((LD>0 & LD>HD)?LD:0,14)*100/SUM(TR,14) + SUM((HD>0 & HD>LD)?HD:0,14)*100/SUM(TR,14))*100,6)\n",
    "#          ,6))/2\n",
    "    dm_plus = data['close'].diff(1).fillna(0)\n",
    "    dm_subtract = data['low'].diff(1).fillna(0)\n",
    "    condition_plus = (dm_plus<dm_subtract) | (dm_plus<0)\n",
    "    condition_sub = (dm_subtract < dm_plus) | (dm_subtract<0)\n",
    "    dm_plus[condition_plus] = 0\n",
    "    dm_subtract[condition_sub] = 0\n",
    "    \n",
    "    close_delay = data['close'].shift(1)\n",
    "    tr_a = data['high'] - data['low']\n",
    "    tr_b = data['high'] - close_delay\n",
    "    tr_c = data['low'] - close_delay\n",
    "    tr = pd.concat([tr_a,tr_b,tr_c],axis=1).max(axis=1)\n",
    "    \n",
    "    tr_sum = tr.rolling(14).sum()\n",
    "    \n",
    "    PDI = dm_plus.rolling(14).sum() * 100 / tr_sum\n",
    "    MDI = dm_subtract.rolling(14).sum() * 100 / tr_sum\n",
    "    DX = np.abs(PDI-MDI)/(PDI+MDI) * 100\n",
    "    ADX = MEAN(DX,6)\n",
    "    ADXR =(ADX+ADX.shift(1))/2\n",
    "    \n",
    "    return ADXR\n",
    "\n",
    "\n",
    "# with pd.option_context('display.max_rows', None): \n",
    "display(excute_for_multidates(df_treated.loc[(slice(None),['000001', '000002', '000063', '000066', '000069', '000100', '000157','000166', '000301', '000333']),:], lambda x: alpha186(x) ,level=1))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
